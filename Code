import cv2
import numpy as np
face_classifier = cv2.CascadeClassifier('C:/Users/Siddharth/Desktop/NEW VISION FOR BLIND/haarcascade_frontalface_default.xml')
def face_extractor(img):
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    faces = face_classifier.detectMultiScale(gray,1.3,5)
    if faces is ():
        return None
    for(x,y,w,h) in faces:
        cropped_face = img[y:y+h, x:x+w]
    return cropped_face
cap = cv2.VideoCapture(0)
count = 0
while True:
    ret, frame = cap.read()
    if face_extractor(frame) is not None:
        count += 1
        face = cv2.resize(face_extractor(frame), (200, 200))
        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
        file_name_path = 'C:/Users/Siddharth/Desktop/NEW VISION FOR BLIND/data/Sid' + str(count) + '.jpg'
        cv2.imwrite(file_name_path, face)
        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)
        cv2.imshow('Face Cropper', face)
    else:
        print("Face not Found")
        pass
    if cv2.waitKey(1) == 13 or count == 200:
        break
cap.release()
cv2.destroyAllWindows()
print('Colleting Samples Complete!!!')


import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
data_path = 'C:/Users/Siddharth/Desktop/NEW VISION FOR BLIND/data/'
onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path,f))]
Training_Data, Labels = [], []
import pyttsx3
def my_speak_cloud(my_message):
    engine = pyttsx3.init()
    rate = engine.getProperty('rate')
    engine.setProperty('rate', rate)
    engine.say('{}'.format(my_message))
    engine.runAndWait()
    #rate = engine.getProperty('rate')
message='''
A Known Person has been Recognized, This is Siddharth Sahu in front of you. '''
message1='''
A Known Person is there, Say hi to unknown person. '''
for i, files in enumerate(onlyfiles):
    image_path = data_path + onlyfiles[i]
    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    Training_Data.append(np.asarray(images, dtype=np.uint8))
    Labels.append(i)
Labels = np.asarray(Labels, dtype=np.int32)
model = cv2.face.LBPHFaceRecognizer_create()
##Local Binary Pattern (LBP) is a simple yet very efficient texture operator which labels the pixels of an image by thresholding the neighborhood of each pixel and considers the result as a binary number.
model.train(np.asarray(Training_Data), np.asarray(Labels))
print("Model Training Complete!!!!!")
face_classifier = cv2.CascadeClassifier('C:/Users/Siddharth/Desktop/NEW VISION FOR BLIND/haarcascade_frontalface_default.xml')
def face_detector(img, size = 2):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_classifier.detectMultiScale(gray,1.3,10)
    if faces is():
        return img,[]
    for(x,y,w,h) in faces:
        cv2.rectangle(img, (x,y),(x+w,y+h),(0,255,255),2)
        roi = img[y:y+h, x:x+w]
        roi = cv2.resize(roi, (200,200))
    return img,roi
cap = cv2.VideoCapture(0)
while True:
    ret, frame = cap.read()
    image, face = face_detector(frame)
    try:
        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
        result = model.predict(face)
        if result[1] < 500:
            confidence = int(100*(1-(result[1])/400))

        k=0
        if confidence > 80:
            display_string = str(confidence) + '% Confidence it is Siddharth'
            cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (250, 120, 255), 2)
            cv2.putText(image, "This is Siddharth", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1,(0, 255, 0), 2)
            cv2.imshow('Face Cropper', image)
            if k==0:
                my_speak_cloud(message)
                k=1
        else:
            display_string = str(confidence) + '% Confidence it is Unknown'
            cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (250, 120, 255), 2)
            cv2.putText(image, "This is Unkonown Person", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0,255), 2)
            cv2.imshow('Face Cropper', image)
            if k==0:
                my_speak_cloud(message1)
                k=1
    except:
        cv2.putText(image, "Face Not Found", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0, 0), 2)
        cv2.imshow('Face Cropper', image)
        pass
    if cv2.waitKey(1)==13:
        break
cap.release()
cv2.destroyAllWindows()







import cv2

cam = cv2.VideoCapture(0)

cv2.namedWindow("test")

img_counter = 0

while True:
    ret, frame = cam.read()
    if not ret:
        print("failed to grab frame")
        break
    cv2.imshow("test", frame)

    k = cv2.waitKey(1)
    if k%256 == 27:
        # ESC pressed
        print("Escape hit, closing...")
        break
    elif k%256 == 32:
        # SPACE pressed
        img_name = "img.png".format(img_counter)
        cv2.imwrite(img_name, frame)
        print("{} written!".format(img_name))
        img_counter += 1

cam.release()

cv2.destroyAllWindows()


import cv2
import pytesseract
import numpy as np
from PIL import ImageGrab
import time

pytesseract.pytesseract.tesseract_cmd = 'C:\Program Files\Tesseract-OCR\\tesseract.exe'
img = cv2.imread('img.png')
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#print(pytesseract.image_to_string(img))

#Detecting Words
hImg, wImg,_ = img.shape
boxes = pytesseract.image_to_data(img)
print(boxes)
boxes = pytesseract.image_to_data(img)
for a,b in enumerate(boxes.splitlines()):
        #print(b)
        if a!=0:
            b = b.split()
            if len(b)==12:
                x,y,w,h = int(b[6]),int(b[7]),int(b[8]),int(b[9])
                cv2.putText(img,b[11],(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)
                cv2.rectangle(img, (x,y), (x+w, y+h), (50, 50, 255), 1)

cv2.imshow("Result",img)
cv2.waitKey(0)



import pytesseract
from PIL import Image
pytesseract.pytesseract.tesseract_cmd = 'C:\Program Files\Tesseract-OCR\\tesseract.exe'
img=Image.open('img.png')
text=pytesseract.image_to_string(img)
print(text)

f= open("iot.txt","w+")
f.write(text)
f.close()

